{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9oq6lKVIOc9"
   },
   "source": [
    "# Lab 02: LSTM - solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26498,
     "status": "ok",
     "timestamp": 1661413339887,
     "user": {
      "displayName": "Chew Kin whye",
      "userId": "16899899049406240390"
     },
     "user_tz": -480
    },
    "id": "N90yKkdNIOdA",
    "outputId": "754e3cb6-8b79-4784-8025-81683226be98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "/content/gdrive/My Drive/Labs/lecture08_labs/lab02_lstm\n",
      "/content/gdrive/.shortcut-targets-by-id/13MZjehRPW2F707gdYdXllrNodq3gbfiq/Labs/lecture08_labs/lab02_lstm\n"
     ]
    }
   ],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    file_name = 'lstm_solution.ipynb'\n",
    "    path_to_file = '/content/gdrive/My Drive/Labs/lecture08_labs/lab02_lstm' # Please adjust the path accordingly \n",
    "    print(path_to_file)\n",
    "    # change current path to the folder containing \"file_name\"\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p0mRA-uEIOdC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import time\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDl78u5SIOdC"
   },
   "source": [
    "### With or without GPU?\n",
    "\n",
    "It is recommended to run this code on GPU:<br> \n",
    "* Time for 1 epoch on CPU : 274 sec ( 4.56 min)<br> \n",
    "* Time for 1 epoch on GPU : 10.1 sec w/ GeForce GTX 1080 Ti <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1661413561637,
     "user": {
      "displayName": "Chew Kin whye",
      "userId": "16899899049406240390"
     },
     "user_tz": -480
    },
    "id": "j2ZpZ4_jIOdC",
    "outputId": "768bb8ed-7bd2-458e-94ac-6a628268de49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dklh6wwbIOdD"
   },
   "source": [
    "### Download Penn Tree Bank\n",
    "\n",
    "The tensor train_data consists of 20 columns of 46,479 words.<br>\n",
    "The tensor test_data consists of 20 columns of 4,121 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1661413562995,
     "user": {
      "displayName": "Chew Kin whye",
      "userId": "16899899049406240390"
     },
     "user_tz": -480
    },
    "id": "SXz-zMNSIOdE",
    "outputId": "58e1180e-f4bc-4ed0-dcd3-8d4831bbc66d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46479, 20])\n",
      "torch.Size([4121, 20])\n"
     ]
    }
   ],
   "source": [
    "from utils import check_ptb_dataset_exists\n",
    "data_path=check_ptb_dataset_exists()\n",
    "\n",
    "train_data  =  torch.load(data_path+'ptb/train_data.pt')\n",
    "test_data   =  torch.load(data_path+'ptb/test_data.pt')\n",
    "\n",
    "print(  train_data.size()  )\n",
    "print(  test_data.size()   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYhwmMtZIOdE"
   },
   "source": [
    "### Some constants associated with the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpzbI9CdIOdF"
   },
   "outputs": [],
   "source": [
    "bs = 20\n",
    "\n",
    "vocab_size = 10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IBezScdIOdF"
   },
   "source": [
    "### Make a recurrent net class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4kDjwseIOdG"
   },
   "outputs": [],
   "source": [
    "class three_layer_recurrent_net(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(three_layer_recurrent_net, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Embedding( vocab_size  , hidden_size  )\n",
    "        self.layer2 = nn.LSTM(      hidden_size , hidden_size  )\n",
    "        self.layer3 = nn.Linear(    hidden_size , vocab_size   )\n",
    "\n",
    "        \n",
    "    def forward(self, word_seq, h_init, c_init ):\n",
    "        \n",
    "        g_seq                      =   self.layer1( word_seq )  \n",
    "        h_seq , (h_final,c_final)  =   self.layer2( g_seq , (h_init,c_init) )      \n",
    "        score_seq                  =   self.layer3( h_seq )\n",
    "        \n",
    "        return score_seq,  h_final , c_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNAK5202IOdG"
   },
   "source": [
    "### Build the net. Choose the hidden size to be 300. How many parameters in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1661413689067,
     "user": {
      "displayName": "Chew Kin whye",
      "userId": "16899899049406240390"
     },
     "user_tz": -480
    },
    "id": "jI1Fs4RhIOdH",
    "outputId": "27cd2af5-b93b-4a56-f037-aa96a817643c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "three_layer_recurrent_net(\n",
      "  (layer1): Embedding(10000, 300)\n",
      "  (layer2): LSTM(300, 300)\n",
      "  (layer3): Linear(in_features=300, out_features=10000, bias=True)\n",
      ")\n",
      "There are 6732400 (6.73 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "hidden_size=300\n",
    "\n",
    "net = three_layer_recurrent_net( hidden_size )\n",
    "\n",
    "print(net)\n",
    "\n",
    "utils.display_num_param(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEVNr4fcIOdH"
   },
   "source": [
    "### Send the weights of the networks to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1M96rZUIOdH"
   },
   "outputs": [],
   "source": [
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vz0cdmk_IOdH"
   },
   "source": [
    "### Set up manually the weights of the embedding module and Linear module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1661413691678,
     "user": {
      "displayName": "Chew Kin whye",
      "userId": "16899899049406240390"
     },
     "user_tz": -480
    },
    "id": "EoF4GcHKIOdH",
    "outputId": "a588fb71-6cc3-4940-e8b8-0d6d11197d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.layer1.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "net.layer3.weight.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6WTRc8bIOdI"
   },
   "source": [
    "### Choose the criterion, as well as the following important hyperparameters: \n",
    "* initial learning rate = 5\n",
    "* sequence length = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFNvkXDRIOdI"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "my_lr = 5\n",
    "\n",
    "seq_length = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2NLzsoxIOdI"
   },
   "source": [
    "### Function to evaluate the network on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhXMb1CJIOdI"
   },
   "outputs": [],
   "source": [
    "def eval_on_test_set():\n",
    "\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "       \n",
    "    h = torch.zeros(1, bs, hidden_size)\n",
    "    c = torch.zeros(1, bs, hidden_size)\n",
    "   \n",
    "    h=h.to(device)\n",
    "    c=c.to(device)\n",
    "       \n",
    "    for count in range( 0 , 4120-seq_length ,  seq_length) :\n",
    "               \n",
    "        minibatch_data =  test_data[ count   : count+seq_length   ]\n",
    "        minibatch_label = test_data[ count+1 : count+seq_length+1 ]\n",
    "        \n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "                                  \n",
    "        scores, h, c  = net( minibatch_data, h , c)\n",
    "        \n",
    "        minibatch_label =   minibatch_label.view(  bs*seq_length ) \n",
    "        scores          =            scores.view(  bs*seq_length , vocab_size)\n",
    "        \n",
    "        loss = criterion(  scores ,  minibatch_label )    \n",
    "        \n",
    "        h=h.detach()\n",
    "        c=c.detach()\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1        \n",
    "    \n",
    "    total_loss = running_loss/num_batches \n",
    "    print('test: exp(loss) = ', math.exp(total_loss)  )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnlT2hFVIOdJ"
   },
   "source": [
    "### Do 8 passes through the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 91607,
     "status": "ok",
     "timestamp": 1661413810123,
     "user": {
      "displayName": "Chew Kin whye",
      "userId": "16899899049406240390"
     },
     "user_tz": -480
    },
    "id": "GOfWMbloIOdJ",
    "outputId": "3dcfb791-0afe-43e0-c6bf-46d834e8406d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch= 0 \t time= 11.140082597732544 \t lr= 5 \t exp(loss)= 280.6248759369808\n",
      "test: exp(loss) =  176.4419702724576\n",
      "\n",
      "epoch= 1 \t time= 22.70071315765381 \t lr= 5 \t exp(loss)= 127.72422078871847\n",
      "test: exp(loss) =  134.33645154480897\n",
      "\n",
      "epoch= 2 \t time= 34.30411648750305 \t lr= 1.6666666666666667 \t exp(loss)= 81.69741853132007\n",
      "test: exp(loss) =  113.9044108536774\n",
      "\n",
      "epoch= 3 \t time= 45.74212694168091 \t lr= 0.5555555555555556 \t exp(loss)= 67.27318404174349\n",
      "test: exp(loss) =  109.63826710104534\n",
      "\n",
      "epoch= 4 \t time= 57.06359672546387 \t lr= 0.1851851851851852 \t exp(loss)= 62.35541427816925\n",
      "test: exp(loss) =  108.09188562028926\n",
      "\n",
      "epoch= 5 \t time= 68.30030012130737 \t lr= 0.0617283950617284 \t exp(loss)= 60.593397063198154\n",
      "test: exp(loss) =  107.40498081555248\n",
      "\n",
      "epoch= 6 \t time= 79.54876613616943 \t lr= 0.0205761316872428 \t exp(loss)= 59.95079200969282\n",
      "test: exp(loss) =  106.9942965091796\n",
      "\n",
      "epoch= 7 \t time= 90.84557461738586 \t lr= 0.006858710562414266 \t exp(loss)= 59.71837276758041\n",
      "test: exp(loss) =  106.76430163274732\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(8):\n",
    "    \n",
    "    # divide the learning rate by 3 except after the first epoch\n",
    "    if epoch >= 2:\n",
    "        my_lr = my_lr / 3\n",
    "    \n",
    "    # create a new optimizer at the beginning of each epoch: give the current learning rate.   \n",
    "    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n",
    "        \n",
    "    # set the running quatities to zero at the beginning of the epoch\n",
    "    running_loss=0\n",
    "    num_batches=0    \n",
    "       \n",
    "    # set the initial h and c to be the zero vector\n",
    "    h = torch.zeros(1, bs, hidden_size)\n",
    "    c = torch.zeros(1, bs, hidden_size)\n",
    "\n",
    "    # send them to the gpu    \n",
    "    h=h.to(device)\n",
    "    c=c.to(device)\n",
    "    \n",
    "    for count in range( 0 , 46478-seq_length ,  seq_length):\n",
    "        \n",
    "        # Set the gradients to zeros\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # create a minibatch\n",
    "        minibatch_data =  train_data[ count   : count+seq_length   ]\n",
    "        minibatch_label = train_data[ count+1 : count+seq_length+1 ]        \n",
    "        \n",
    "        # send them to the gpu\n",
    "        minibatch_data=minibatch_data.to(device)\n",
    "        minibatch_label=minibatch_label.to(device)\n",
    "        \n",
    "        # Detach to prevent from backpropagating all the way to the beginning\n",
    "        # Then tell Pytorch to start tracking all operations that will be done on h and c\n",
    "        h=h.detach()\n",
    "        c=c.detach()\n",
    "        # h=h.requires_grad_()\n",
    "        # c=c.requires_grad_()\n",
    "                       \n",
    "        # forward the minibatch through the net        \n",
    "        scores, h, c  = net( minibatch_data, h , c)\n",
    "        \n",
    "        # reshape the scores and labels to huge batch of size bs*seq_length\n",
    "        scores          =            scores.view(  bs*seq_length , vocab_size)  \n",
    "        minibatch_label =   minibatch_label.view(  bs*seq_length )       \n",
    "        \n",
    "        # Compute the average of the losses of the data points in this huge batch\n",
    "        loss = criterion(  scores ,  minibatch_label )\n",
    "        \n",
    "        # backward pass to compute dL/dR, dL/dV and dL/dW\n",
    "        loss.backward()\n",
    "\n",
    "        # do one step of stochastic gradient descent: R=R-lr(dL/dR), V=V-lr(dL/dV), ...\n",
    "        utils.normalize_gradient(net)\n",
    "        optimizer.step()\n",
    "        \n",
    "            \n",
    "        # update the running loss  \n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    # compute stats for the full training set\n",
    "    total_loss = running_loss/num_batches\n",
    "    elapsed = time.time()-start\n",
    "    \n",
    "    print('')\n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'\\t lr=', my_lr, '\\t exp(loss)=',  math.exp(total_loss))\n",
    "    eval_on_test_set() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl0oGMnBIOdK"
   },
   "source": [
    "### Choose one sentence (taken from the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCLdfbWFIOdK"
   },
   "outputs": [],
   "source": [
    "# SENTENCES FROM TEST SET\n",
    "\n",
    "sentence1 = \"some analysts expect oil prices to remain relatively\"\n",
    "\n",
    "sentence2 = \"over the next days and weeks they say investors should look for stocks to\"\n",
    "\n",
    "sentence2 = \"some analysts expect oil prices to remain relatively\"\n",
    "\n",
    "sentence3 = \"prices averaging roughly $ N a barrel higher in the third\"\n",
    "\n",
    "sentence4 = \"i think my line has been very consistent mrs. hills said at a news\"\n",
    "\n",
    "sentence5 = \"this appears particularly true at gm which had strong sales in\"\n",
    "\n",
    "# OR MAKE YOUR OWN SENTENCE. \n",
    "# NO CAPITAL LETTER ALLOWED. EACH WORD MUST BE IN THE ALLOWED VOCABULARY OF 10,000 WORDS\n",
    "\n",
    "sentence6= \"he was very\"\n",
    "\n",
    "\n",
    "# CHOOSE THE SENTENCE\n",
    "mysentence = sentence1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lotgf11BIOdK"
   },
   "source": [
    "### Convert the sentence into a vector, then send to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y2LJCrxyIOdK",
    "outputId": "a961ef73-a19a-4258-c3a3-a597adffb11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 307],\n",
      "        [1140],\n",
      "        [ 334],\n",
      "        [1486],\n",
      "        [1786],\n",
      "        [  64],\n",
      "        [ 719],\n",
      "        [ 377]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "minibatch_data=utils.sentence2vector(mysentence)\n",
    "      \n",
    "minibatch_data=minibatch_data.to(device)\n",
    "\n",
    "print(minibatch_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A4qKoqSIOdK"
   },
   "source": [
    "### Set the initial hidden state to zero, then run the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFjKNHspIOdL"
   },
   "outputs": [],
   "source": [
    "h = torch.zeros(1, 1, hidden_size)\n",
    "c = torch.zeros(1, 1, hidden_size)\n",
    "h=h.to(device)\n",
    "c=c.to(device)\n",
    "\n",
    "scores , h, c = net(minibatch_data , h, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaLP5_mAIOdL"
   },
   "source": [
    "### Display the network prediction for the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RQ-PK1j9IOdL",
    "outputId": "0699b4f0-7c79-4b5d-8cbf-952159b668ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some analysts expect oil prices to remain relatively ... \n",
      "\n",
      "11.3%\t <unk>\n",
      "6.2%\t high\n",
      "4.4%\t strong\n",
      "2.3%\t small\n",
      "2.1%\t good\n",
      "1.9%\t low\n",
      "1.5%\t large\n",
      "1.4%\t heavy\n",
      "1.2%\t competitive\n",
      "0.9%\t longer\n",
      "0.9%\t major\n",
      "0.9%\t volatile\n",
      "0.9%\t thin\n",
      "0.9%\t well\n",
      "0.8%\t profitable\n",
      "0.8%\t greater\n",
      "0.8%\t short\n",
      "0.7%\t bullish\n",
      "0.6%\t flat\n",
      "0.6%\t weak\n",
      "0.6%\t bad\n",
      "0.6%\t little\n",
      "0.6%\t larger\n",
      "0.6%\t hard\n",
      "0.6%\t stable\n",
      "0.5%\t fairly\n",
      "0.5%\t cheap\n",
      "0.5%\t positive\n",
      "0.5%\t great\n",
      "0.5%\t costly\n"
     ]
    }
   ],
   "source": [
    "print(mysentence, '... \\n')\n",
    "\n",
    "utils.show_next_word(scores)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
