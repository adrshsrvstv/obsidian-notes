1. 
    a) A light weight UAV: Typically low cost, lightweight, will likely only be used within a a couple hundred feet off the ground. In this case, an IMU with integrated barometer for coarse height readings such as that needed for higher altitude readings, and a a low cost ultrasonic sensor which can be used for finer readings when the UAV is closer to the surface. A combination of these two will be low cost and lightweight enough to fit and serve the use cases of a small UAV
    b) A full-size outdoor UAV, such as those used for delivering packages, spying on enemy lines in a war, or spraying crops with pesticides  - need a high degree of precision at low altitudes, but at the same time, can potentially reach altitudes high enough that LIDAR data might become noisy. Cost is typically not an issue with such high performance UAVs. In this case, a combination of lidar, barometer, along with GPS data will cover both low and high altitude requirements to maintain height.

2. a)  $p_0=[0.5, 0.5]$ 

  Tiger doesn't move, so state transition matrix $T$ is  identity matrix $I_2$, in other words $p_n = p_0 = [0.5, 0.5]$ as far as prediction update is concerned.
  Further, the state-observation model is:

| State/Observation      | TL   | TR   |
| ---------------------- | ---- | ---- |
| L  (Tiger is on left)  | 0.85 | 0.15 |
| R  (Tiger is on right) | 0.15 | 0.85 |
|                        |      |      |

At time step $t=1$: $$ p_1(S_1=L | Z = TL) = \eta p(Z = TL | S_1 = L)*p(S_1=L) = \eta * 0.85* 0.5 $$ and $$p_1(S_1 = R | Z = TL) = \eta p(Z = TL | S_1 = R)*p(S_1=R) = \eta * 0.15* 0.5$$ 
Normalizing gives, $$p_1 = [0.85, 0.15]$$
Similarly, at time step $t=2:$ $$p_2 = [\eta * 0.15*0.85, \eta * 0.85* 0.15] = [0.5, 0.5]$$
And at time step $t=3$, we have: $$p_3 = [\eta * 0.15*0.5, \eta * 0.85* 0.5] = [0.15, 0.85]$$

b) If the tiger is allowed to move, we now also have a non-identity state transition model $T$ like so:


|       | $S_1$ | $S_2$ |
| ----- | ----- | ----- |
| $S_1$ | 0.9   | 0.1   |
| $S_2$ | 0.1   | 0.9   |

At time step $t=1:$
Prediction update yields  $$p_1 = p_0T = [0.5, 0.5]$$
Observation update yields $$p_1 = [\eta * 0.85*0.5, \eta * 0.15* 0.5] = [0.85, 0.15]$$
At time step $t=2:$
Prediction update yields: $$p_2 = p_1T = [\eta * 0.85*0.9 + 0.15*0.1, \eta * 0.85*0.1 + 0.15*0.9] =[0.78, 0.22]$$
Observation update yields: $$p_2 = [\eta * 0.15*0.78, \eta * 0.85* 0.22] = [0.385, 0.615]$$
At time step $t=3:$
Prediction update yields: $$p_3 = p_2T = [\eta * 0.385*0.9 + 0.615*0.1, \eta * 0.385*0.1 + 0.615*0.9] =[0.408, 0.592]$$   
Observation update yields: $$p_3 = [\eta * 0.15*0.408, \eta * 0.85* 0.592] = [0.108, 0.892]$$

3. Robot is stationary, so state doesn't change from initial state, or in other words: $$ p(S_t = s' | S_{t-1} = s) = 1 \text{ if } s'=s = s_0$$ Further, no observation is made. We can take this as there existing only a single observation irrespective of state or time-step - that observation being $z_\phi$ - null observation, with $P(Z_t=z_\phi | S_t = s) = 1$ for all $s \in S$. So, $$ p(S_t=s | Z_t = z_\phi) = P(Z_t=z_\phi | S_t = s)P(S_t = s) = P(S_t = s)$$
     Initial particle weights = $[\frac{1}{2},\frac{1}{2}]$
      a) Prediction update after initial sampling: $p = [0.5, 0.5]$ since no state transitions are possible
      Observation update, again, yields $p=[0.5, 0.5]$
      Resampling two particles from the two states $s_1$ and $s_2$ with probability $0.5$ for each.
	      1. Probability of both samples belonging to same state = $$p(s_1) * p(s_1) + p(s_2) * p(s_2) = 0.5*0.5 + 0.5*0.5 = 0.5$$
	      2. So, probability that the samples belong to different states: $$p(s_1) * p(s_2) + p(s_2) * p(s_1) = 0.5*0.5 + 0.5*0.5 = 0.5$$
        b)  If we do another step after above step, in case the particles belonged to the same state, any further particles sampled will also belong to that same state.
        In case the particles belonged to different states, we'll have a repeat of the above calculations, with all probabilities multiplied by $0.5$ (the probability of particles belonging to different states).
        So, after two steps, probability that the particles belong to different states = $(\frac{1}{2})^2$ .
        Extending this, for N steps, the probabilities of different and same states will be  $(\frac{1}{2})^N$ and $1-(\frac{1}{2})^N$ respectively.
        c) With each particle resampling step, we notice that the probability that they'll belong to different states is exponentially decreasing. Further, because there are no state transitions possible and no observations, we always sample from the same states we sampled initially, with increasing probabilities that all of our sampled particles may belong to a single state.
        This may look like the filter has uniquely determined a state, or at least zeroed down on a few most likely states. However, the true state may be neither of the currently sampled states. This is obviously a problem since we get no closer to the truth with each resampling, and in fact get farther from it if the true state wasn't among the initially sampled states.
        d) As long as we do importance resampling without observation and without state changes, it is guaranteed that the variation in samples will reduce with every importance resampling - the probability for all K samples belonging to the same state over N steps would be $1-(1-\frac{1}{K^{K-1}} )^N$ , which approaches $1$ asymptotically.
        e) One option could be to randomly sample a few particles every resampling step irrespective of weights. Another option could be to only resample if the variance in the states of the particles is above a certain threshold.
	
4.  The choice of filters is as follows:
	a) The state is determined by the distance from the center of the lane and so the state space is continuous. Further, it is reasonable to assume that the real lane position determined from camera input observation will follow a gaussian distribution - because the distribution have a peak around the real position, and decay slowly from there . Further, it can be reasonably assumed that while the car is driven, the uncertainty and errors are going to be relatively small from previous states. Therefore, Kalman filters are a good candidate for this kind of localization.
	b) The state, action space are discrete - DECELERATE or ACCELERATE are the possible states, TURN or NOT_TURN are the possible actions. Further, observation can be discretized by ranges on the observed relative acceleration - between 0 and 5m/s, between 5 and 15m/s, etc. and thus a observation-state model can be arrived at. In this case, histogram filter or HMMs are ideally suited since, given accurate transition and observation-state models, the result is accurate and tractable.
	c) Since the state space is continuous and very large and uncertainty in robot position is also large (the robot is lost), particle filtering should be used. 
5. 
a) States: $H$ for hungry, $\bar{H}$ for Not Hungry
	Actions: $F$ for Feed, $\bar{F}$ for Not  Feed
	Observations: $C$ for crying, $\bar{C}$ for not crying
b) 

| state transition   | $H$    | $\bar{H}$ |
| ------------------ | ------ | --------- |
| $H$, $F$           | $0$    | $1$       |
| $H, \bar{F}$       | $1$   | $0$       |
| $\bar{H}, F$       | $0$    | $1$       |
| $\bar{H}, \bar{F}$ | $0.05$ | $0.95$    |

c)
   
| State/Observation | $C$    | $\bar{C}$ |
| ----------------- | ------ | --------- |
| $H$               | $0.8$  | $0.2$     |
| $\bar{H}$         | $0.15$ | $0.85$    |

  d)  
       
   | State/action | $F$ | $\bar{F}$ |
   | ------------ | --- | --------- |
   | $H$          |   $3$  |      $2$     |
   | $\bar{H}$             |  $1$   |       $0$    |


6. a) Since there are no observations, and state transitions depend only on the actions, MDP is a suitable model for the problem.
    b) Assuming the robot is facing forward (in the direction in which it can move) at the start position, one policy that takes it to $T$ and keeps it there is  ($F$=Forward, $L$=Left, $R$=Right. Assume robot only translates and never rotates)
    $$F, F, F, L, L , L, L, R, R, StayPut$$